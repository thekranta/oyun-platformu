import { Ionicons } from '@expo/vector-icons';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import React, { useEffect, useRef, useState } from 'react';
import { Animated, Image, Platform, StyleSheet, Text, TouchableOpacity, View } from 'react-native';
import DynamicBackground from './DynamicBackground';
import ProgressBar from './ProgressBar';

// A≈üama Verileri
const STAGES = [
    { id: 1, image: require('../assets/images/elma.png'), word: 'Elma' },
    { id: 2, image: require('../assets/images/araba.png'), word: 'Araba' },
    { id: 3, image: require('../assets/images/kedi.png'), word: 'Kedi' },
    { id: 4, image: require('../assets/images/top.png'), word: 'Top' },
    { id: 5, image: require('../assets/images/ev.png'), word: 'Ev' },
];

interface BunuSoyleProps {
    onGameEnd: (oyunAdi: string, sure: number, finalHamle: number, finalHata: number, algilananKelime: string) => void;
    onExit: () => void;
}

export default function BunuSoyle({ onGameEnd, onExit }: BunuSoyleProps) {
    const [currentStage, setCurrentStage] = useState(0);
    const [isRecording, setIsRecording] = useState(false);
    const [recordingStatus, setRecordingStatus] = useState('Kayƒ±t Hazƒ±r');
    const [startTime] = useState(Date.now());
    const [moves, setMoves] = useState(0);
    const [errors, setErrors] = useState(0);
    const [allTranscripts, setAllTranscripts] = useState<string[]>([]);
    const [permissionResponse, requestPermission] = Audio.usePermissions();

    // Recording Ref: Asenkron i≈ülemlerde state'in g√ºncel olmama sorununu √ß√∂zmek i√ßin
    const recordingRef = useRef<Audio.Recording | null>(null);

    const [audioLevels, setAudioLevels] = useState<number[]>([0, 0, 0, 0, 0]);
    const [maxAudioLevel, setMaxAudioLevel] = useState(-160);

    // Animasyon deƒüerleri
    const barAnims = useRef([
        new Animated.Value(10),
        new Animated.Value(10),
        new Animated.Value(10),
        new Animated.Value(10),
        new Animated.Value(10)
    ]).current;

    const autoStopTimer = useRef<NodeJS.Timeout | null>(null);
    const currentItem = STAGES[currentStage];

    // ƒ∞zin kontrol√º
    useEffect(() => {
        (async () => {
            if (!permissionResponse) {
                await requestPermission();
            }
        })();
    }, []);

    // A≈üama deƒüi≈ütiƒüinde otomatik ba≈ülat
    useEffect(() => {
        let isMounted = true;

        const initStage = async () => {
            // √ñnceki kaydƒ± temizle
            await stopRecording(false);

            if (isMounted) {
                // Kƒ±sa bir gecikme ile yeni kaydƒ± ba≈ülat (Race condition √∂nlemek i√ßin)
                setTimeout(() => {
                    if (isMounted) startRecording();
                }, 500);
            }
        };

        initStage();

        return () => {
            isMounted = false;
            if (autoStopTimer.current) clearTimeout(autoStopTimer.current);
            // Cleanup sƒ±rasƒ±nda asenkron durdurma yapƒ±yoruz ama await edemeyiz
            // Bu y√ºzden best-effort durdurma yapƒ±yoruz
            if (recordingRef.current) {
                recordingRef.current.stopAndUnloadAsync().catch(() => { });
                recordingRef.current = null;
            }
        };
        // eslint-disable-next-line react-hooks/exhaustive-deps
    }, [currentStage]);

    // Ses seviyesi g√∂rselle≈ütirmesi
    useEffect(() => {
        if (isRecording) {
            const animations = barAnims.map((anim, index) => {
                const targetHeight = 20 + (audioLevels[index] * 100) + (Math.random() * 30);
                return Animated.timing(anim, {
                    toValue: Math.min(targetHeight, 120),
                    duration: 100,
                    useNativeDriver: false,
                });
            });
            Animated.parallel(animations).start();
        } else {
            const animations = barAnims.map(anim =>
                Animated.timing(anim, {
                    toValue: 10,
                    duration: 200,
                    useNativeDriver: false,
                })
            );
            Animated.parallel(animations).start();
        }
    }, [audioLevels, isRecording]);

    const startRecording = async () => {
        try {
            console.log('üéôÔ∏è Kayƒ±t ba≈ülatƒ±lƒ±yor...');
            console.log('ƒ∞zin durumu:', permissionResponse?.status);

            // Mevcut kayƒ±t varsa temizle
            if (recordingRef.current) {
                try {
                    await recordingRef.current.stopAndUnloadAsync();
                } catch (e) {
                    // Zaten durmu≈üsa sorun yok
                }
                recordingRef.current = null;
            }

            if (permissionResponse?.status !== 'granted') {
                console.log('‚ùå Mikrofon izni yok, izin isteniyor...');
                const newPermission = await requestPermission();
                console.log('Yeni izin durumu:', newPermission?.status);
                if (newPermission?.status !== 'granted') {
                    setRecordingStatus('Mikrofon ƒ∞zni Gerekli üé§');
                    setIsRecording(false);
                    return;
                }
            }

            await Audio.setAudioModeAsync({
                allowsRecordingIOS: true,
                playsInSilentModeIOS: true,
            });

            const recordingOptions = {
                ...Audio.RecordingOptionsPresets.HIGH_QUALITY,
                isMeteringEnabled: true,
            };

            console.log('üìù Audio.Recording.createAsync √ßaƒürƒ±lƒ±yor...');
            const { recording: newRecording } = await Audio.Recording.createAsync(
                recordingOptions,
                (status) => {
                    if (status.isRecording) {
                        let metering = status.metering;

                        // WEB Sƒ∞M√úLASYONU
                        if (Platform.OS === 'web' || metering === undefined) {
                            metering = -40 + Math.random() * 30;
                        }

                        const level = Math.max(0, (metering + 160) / 160);
                        setMaxAudioLevel(prev => Math.max(prev, metering));

                        setAudioLevels([
                            level * 0.8,
                            level * 1.2,
                            level * 1.5,
                            level * 1.2,
                            level * 0.8
                        ]);
                    }
                },
                100
            );

            console.log('‚úÖ Kayƒ±t ba≈üarƒ±yla olu≈üturuldu');
            recordingRef.current = newRecording;
            setIsRecording(true);
            setRecordingStatus('Sƒ∞STEM Dƒ∞NLƒ∞YOR...');
            setMaxAudioLevel(-160);

            if (autoStopTimer.current) clearTimeout(autoStopTimer.current);
            autoStopTimer.current = setTimeout(() => {
                stopRecording(true);
            }, 3000);

        } catch (err) {
            console.error('‚ùå Kayƒ±t ba≈ülatƒ±lamadƒ±:', err);
            // Hata olsa bile kullanƒ±cƒ±ya tekrar deneme ≈üansƒ± ver
            setIsRecording(false);
            setRecordingStatus('Mikrofona Dokun üî¥');
        }
    };

    const stopRecording = async (shouldAnalyze = true) => {
        if (autoStopTimer.current) clearTimeout(autoStopTimer.current);

        let audioUri: string | null = null;

        try {
            if (recordingRef.current) {
                const uri = recordingRef.current.getURI();
                audioUri = uri;
                await recordingRef.current.stopAndUnloadAsync();
                recordingRef.current = null;
            }
        } catch (error) {
            // Hata √∂nemsiz, zaten durmu≈ü olabilir
            console.log("Durdurma hatasƒ± (handle edildi):", error);
        }

        setIsRecording(false);

        if (shouldAnalyze && audioUri) {
            setRecordingStatus('Analiz Ediliyor...');
            analyzeSpeech(currentItem.word, audioUri);
        }
    };

    const handleRetry = () => {
        startRecording();
    };

    const analyzeSpeech = async (beklenenKelime: string, audioUri: string) => {
        // SESSƒ∞ZLƒ∞K KONTROL√ú
        console.log("Maksimum Ses Seviyesi:", maxAudioLevel);

        if (maxAudioLevel < -50) {
            setRecordingStatus('Ses Algƒ±lanmadƒ± üîá');
            setErrors(e => e + 1);
            setAllTranscripts(prev => [...prev, "(Sessiz)"]);
            setMoves(m => m + 1);

            // Otomatik olarak bir sonraki a≈üamaya ge√ß
            setTimeout(() => {
                handleNextStage();
            }, 2000);
            return;
        }

        try {
            // Platform-specific Base64 encoding
            let base64Audio: string;

            if (Platform.OS === 'web') {
                // WEB: fetch + FileReader kullan
                console.log('üåê Web platformu tespit edildi, fetch kullanƒ±lƒ±yor...');
                const response = await fetch(audioUri);
                const blob = await response.blob();

                base64Audio = await new Promise<string>((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                        const result = reader.result as string;
                        // "data:audio/...;base64," ba≈ülƒ±ƒüƒ±nƒ± temizle
                        const base64 = result.split(',')[1];
                        resolve(base64);
                    };
                    reader.onerror = reject;
                    reader.readAsDataURL(blob);
                });
            } else {
                // MOBILE: expo-file-system kullan
                console.log('üì± Mobil platform tespit edildi, FileSystem kullanƒ±lƒ±yor...');
                base64Audio = await FileSystem.readAsStringAsync(audioUri, {
                    encoding: 'base64',
                });
            }

            // Google Speech-to-Text API √ßaƒürƒ±sƒ±
            const apiKey = process.env.EXPO_PUBLIC_SPEECH_API_KEY;
            if (!apiKey) {
                throw new Error('API key bulunamadƒ±');
            }

            console.log('üé§ Google Speech-to-Text API √ßaƒürƒ±lƒ±yor...');
            const response = await fetch(
                `https://speech.googleapis.com/v1/speech:recognize?key=${apiKey}`,
                {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        config: {
                            encoding: Platform.OS === 'web' ? 'WEBM_OPUS' : 'LINEAR16',
                            sampleRateHertz: Platform.OS === 'web' ? 48000 : 44100,
                            languageCode: 'tr-TR',
                        },
                        audio: {
                            content: base64Audio,
                        },
                    }),
                }
            );

            const data = await response.json();
            console.log('üì• API Yanƒ±tƒ±:', data);

            // Transcript'i √ßƒ±kar
            let transcript = '';
            if (data.results && data.results.length > 0) {
                transcript = data.results[0].alternatives[0].transcript || '';
            }

            if (!transcript) {
                transcript = '(Anla≈üƒ±lamadƒ±)';
            }

            console.log('‚úÖ Algƒ±lanan kelime:', transcript);
            setAllTranscripts(prev => [...prev, transcript]);

            const temizlenenTranscript = transcript.toLowerCase().trim();
            const temizlenenBeklenen = beklenenKelime.toLowerCase().trim();

            // Her durumda hareketi kaydet
            setMoves(m => m + 1);

            if (temizlenenTranscript === temizlenenBeklenen) {
                // Doƒüru cevap - hata yok
                setRecordingStatus('Harika! üéâ');
                setTimeout(() => handleNextStage(), 2000);
            } else {
                // Yanlƒ±≈ü cevap - hata kaydet ve yine de devam et
                setErrors(e => e + 1);
                setRecordingStatus(`Tekrar Dene ‚ùå ("${transcript}")`);
                // Otomatik olarak bir sonraki a≈üamaya ge√ß
                setTimeout(() => handleNextStage(), 2000);
            }
        } catch (error) {
            console.error('‚ùå Speech API hatasƒ±:', error);
            // Hata durumunda bile kaydet ve devam et
            setAllTranscripts(prev => [...prev, '(API Hatasƒ±)']);
            setErrors(e => e + 1);
            setMoves(m => m + 1);
            setRecordingStatus('API Hatasƒ± ‚ö†Ô∏è');
            setTimeout(() => handleNextStage(), 2000);
        }
    };

    const handleNextStage = () => {
        if (currentStage < STAGES.length - 1) {
            setCurrentStage(prev => prev + 1);
        } else {
            const duration = Math.floor((Date.now() - startTime) / 1000);
            const finalTranscriptString = allTranscripts.join(", ");
            onGameEnd('bunu-soyle', duration, moves, errors, finalTranscriptString);
        }
    };

    return (
        <DynamicBackground onExit={onExit}>
            <View style={styles.topBar}>
                <ProgressBar current={currentStage + 1} total={STAGES.length} />
            </View>

            <View style={styles.container}>
                <Text style={styles.title}>Bunu S√∂yle! üéôÔ∏è</Text>
                <Text style={styles.subtitle}>Resimdeki nedir?</Text>

                <View style={styles.card}>
                    <View style={styles.imageContainer}>
                        <Image source={currentItem.image} style={styles.image} resizeMode="contain" />
                    </View>
                    <Text style={styles.targetWord}>{currentItem.word}</Text>
                </View>

                <View style={styles.controlsContainer}>
                    {isRecording ? (
                        <View style={styles.recordingFeedback}>
                            <Text style={styles.promptText}>≈ûƒ∞MDƒ∞ S√ñYLE: {currentItem.word}</Text>
                            <View style={styles.visualizerContainer}>
                                <View style={styles.barsContainer}>
                                    {barAnims.map((anim, index) => (
                                        <Animated.View
                                            key={index}
                                            style={[
                                                styles.visualizerBar,
                                                { height: anim }
                                            ]}
                                        />
                                    ))}
                                </View>
                                <Text style={styles.listeningText}>Sƒ∞STEM Dƒ∞NLƒ∞YOR...</Text>
                            </View>
                        </View>
                    ) : (
                        <TouchableOpacity
                            style={styles.recordButton}
                            onPress={handleRetry}
                            activeOpacity={0.7}
                        >
                            <Ionicons name="mic" size={50} color="white" />
                        </TouchableOpacity>
                    )}

                    <Text style={[
                        styles.statusText,
                        isRecording && styles.statusRecording,
                        recordingStatus === 'Analiz Ediliyor...' && styles.statusProcessing,
                        recordingStatus === 'Harika! üéâ' && styles.statusSuccess,
                        recordingStatus === 'Tekrar Dene ‚ùå' && styles.statusError,
                        recordingStatus === 'Ses Algƒ±lanmadƒ± üîá' && styles.statusError
                    ]}>
                        {recordingStatus}
                    </Text>
                </View>
            </View>
        </DynamicBackground>
    );
}

const styles = StyleSheet.create({
    topBar: {
        width: '100%',
        paddingTop: 40,
        paddingBottom: 10,
        backgroundColor: 'rgba(255,255,255,0.8)',
        zIndex: 10,
    },
    container: {
        flex: 1,
        alignItems: 'center',
        paddingTop: 20,
        paddingHorizontal: 20,
    },
    title: {
        fontSize: 32,
        fontWeight: 'bold',
        color: '#2C3E50',
        marginBottom: 5,
    },
    subtitle: {
        fontSize: 18,
        color: '#555',
        marginBottom: 30,
    },
    card: {
        backgroundColor: 'white',
        borderRadius: 25,
        padding: 20,
        alignItems: 'center',
        width: '90%',
        elevation: 8,
        shadowColor: '#000',
        shadowOffset: { width: 0, height: 4 },
        shadowOpacity: 0.2,
        shadowRadius: 5,
        marginBottom: 30,
    },
    imageContainer: {
        width: 180,
        height: 180,
        justifyContent: 'center',
        alignItems: 'center',
        marginBottom: 20,
        backgroundColor: '#F5F5F5',
        borderRadius: 20,
        overflow: 'hidden',
    },
    image: {
        width: '100%',
        height: '100%',
    },
    targetWord: {
        fontSize: 36,
        fontWeight: 'bold',
        color: '#34495E',
        letterSpacing: 1,
    },
    controlsContainer: {
        alignItems: 'center',
        width: '100%',
        height: 200,
        justifyContent: 'flex-start',
    },
    recordButton: {
        width: 90,
        height: 90,
        borderRadius: 45,
        backgroundColor: '#E74C3C',
        justifyContent: 'center',
        alignItems: 'center',
        elevation: 10,
        shadowColor: '#E74C3C',
        shadowOffset: { width: 0, height: 5 },
        shadowOpacity: 0.4,
        shadowRadius: 8,
        marginBottom: 20,
        borderWidth: 4,
        borderColor: 'white',
    },
    recordingFeedback: {
        alignItems: 'center',
        width: '100%',
    },
    promptText: {
        fontSize: 28,
        fontWeight: 'bold',
        color: '#E74C3C',
        marginBottom: 20,
        textAlign: 'center',
        letterSpacing: 0.5,
    },
    waitingContainer: {
        alignItems: 'center',
        justifyContent: 'center',
        height: 120,
        marginBottom: 10,
    },
    waitingText: {
        fontSize: 22,
        fontWeight: '600',
        color: '#95A5A6',
        letterSpacing: 1,
    },
    visualizerContainer: {
        alignItems: 'center',
        justifyContent: 'center',
        height: 120,
        marginBottom: 10,
    },
    barsContainer: {
        flexDirection: 'row',
        alignItems: 'flex-end',
        justifyContent: 'center',
        height: 80,
        marginBottom: 10,
        gap: 8,
    },
    visualizerBar: {
        width: 12,
        backgroundColor: '#E74C3C',
        borderRadius: 6,
    },
    listeningText: {
        fontSize: 18,
        fontWeight: 'bold',
        color: '#E74C3C',
        letterSpacing: 1,
    },
    statusText: {
        fontSize: 20,
        fontWeight: '600',
        color: '#7F8C8D',
        textAlign: 'center',
    },
    statusRecording: { color: '#E74C3C', fontWeight: 'bold' },
    statusProcessing: { color: '#F39C12', fontWeight: 'bold' },
    statusSuccess: { color: '#2ECC71', fontWeight: 'bold' },
    statusError: { color: '#E74C3C', fontWeight: 'bold' }
});
